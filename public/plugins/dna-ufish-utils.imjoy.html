<config lang="json">
{
    "name": "dna-ufish-utils",
    "type": "web-python",
    "tags": [],
    "flags": [],
    "ui": "",
    "version": "0.1.0",
    "cover": "",
    "description": "utils for analyzing dna fish data using ufish model",
    "icon": "extension",
    "inputs": null,
    "outputs": null,
    "api_version": "0.1.8",
    "env": "",
    "permissions": [],
    "requirements": ["numpy", "imjoy-rpc", "scikit-image", "scikit-learn", "matplotlib"],
    "dependencies": []
}
</config>

<script lang="python">
from imjoy import api

import io
import base64
import os
from sklearn.neighbors import KDTree
from scipy.spatial.distance import cdist
from skimage.measure import regionprops, label
from skimage.morphology import diamond, ball, dilation, square, disk
from functools import reduce
from skimage.segmentation import watershed
import numpy as np
import random
import matplotlib
matplotlib.use("module://matplotlib_pyodide.wasm_backend")


def extract_cells(
        image: np.ndarray, mask: np.ndarray,
        target_size=128,
        ):
    cell_rois = []
    cell_props = []
    cell_masks = []

    props = regionprops(mask)

    for prop in props:
        y0, x0, y1, x1 = prop.bbox
        w, h = x1 - x0, y1 - y0
        long_side = max(w, h)
        if long_side > target_size:
            continue
        roi = np.zeros(
            (target_size, target_size, image.shape[2]),
            dtype=image.dtype
        )
        start_y = (target_size - h) // 2
        start_x = (target_size - w) // 2
        coords = prop.coords
        roi_y = coords[:, 0] - y0 + start_y
        roi_x = coords[:, 1] - x0 + start_x
        roi[roi_y, roi_x, :] = image[coords[:, 0], coords[:, 1], :]
        cell_rois.append(roi)
        cell_props.append(prop)
        cell_mask = np.zeros((target_size, target_size), dtype=np.uint8)
        cell_mask[roi_y, roi_x] = 1
        cell_masks.append(cell_mask)
    return cell_rois, cell_masks, cell_props


def cc_sub(im: np.ndarray, seed: np.ndarray, connectivity=2) -> np.ndarray:
    """Subtract the Connected Components in image which overlap with seed.

    :param im: mask image to be subtract CC.
    :param seed: mask image.
    :param connectivity: connectivity to calculate label, see:
    https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.label

    :return: CC in im without overlap with seed.
    """
    lb = label(seed, connectivity=connectivity)
    w = watershed(im, markers=lb, connectivity=connectivity, mask=im)
    o = w > 0
    d = im ^ o
    return d


def mask_sub(oriangal: np.ndarray,
             masks: list[np.ndarray],
             ) -> np.ndarray:
    o = oriangal
    for m in masks:
        o = cc_sub(o, m)
    return o


def coordinates_to_mask(
        points: np.ndarray, shape: tuple | None = None) -> np.ndarray:
    points = points.astype(np.int64)
    dim_max = tuple([points[:, i].max()+1 for i in range(points.shape[1])])
    if shape is None:
        shape = dim_max
    else:
        assert len(shape) == points.shape[1]
        shape = tuple([shape[i] or dim_max[i] for i in range(points.shape[1])])
    arr = np.zeros(shape, dtype=np.bool_)
    ix = tuple(points[:, d] for d in range(points.shape[1]))
    arr[ix] = True
    return arr


def cc_centroids(mask: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
    if mask.dtype == bool:
        mask = label(mask.astype(int))
    ccs = regionprops(mask)
    centroids, labels = [], []
    for cc in ccs:
        centroids.append(cc.centroid)
        labels.append(cc.label)
    return np.array(centroids), np.array(labels)


def spots_sub(spots_a: np.ndarray, spots_b: np.ndarray, radius: int):
    assert spots_a.shape[1] == spots_b.shape[1]
    dim = spots_a.shape[1]
    assert 2 <= dim <= 3
    shape = tuple([max([int(pts[:, i].max()) for pts in [spots_a, spots_b]]) + 1
                   for i in range(dim)])
    mask_a = coordinates_to_mask(spots_a, shape)
    se = diamond(radius) if dim == 2 else ball(radius)
    mask_a = dilation(mask_a, se)
    mask_b = coordinates_to_mask(spots_b, shape)
    res_mask = mask_sub(mask_a, [mask_b])
    return cc_centroids(res_mask)[0]


async def call_spots(ufish_instance, img, ch=[0, 1]):
    """Call spots using ufish model."""
    uf = ufish_instance
    spots_list = []
    for c in ch:
        res = await uf.predict(img[:, :, c], None, 0.5, True)
        spots = res['spots']
        spots_list.append(spots)
    return spots_list


def get_merge_spots(spots_list, max_dist=2.0, ch=[0, 1]):
    """Get the coordinates of all merged spots from multiple channels."""
    spots_ch1 = spots_list[ch[0]]
    spots_ch2 = spots_list[ch[1]]
    tree = KDTree(spots_ch1)
    dist, ind = tree.query(spots_ch2, k=1)
    merge_spots = spots_ch1[ind[dist < max_dist]]
    if len(ch) == 3:
        spots_ch3 = spots_list[ch[2]]
        tree = KDTree(merge_spots)
        dist, ind = tree.query(spots_ch3, k=1)
        merge_spots = merge_spots[ind[dist < max_dist]]
    return merge_spots


def assign_spots(
        spots: np.ndarray,
        mask: np.ndarray,
        dist_th: float,
        ) -> np.ndarray:
    assert len(mask.shape) in (2, 3)
    centers, labels = cc_centroids(mask)
    assert centers.shape[1] == len(mask.shape)
    pos_each_axes = np.where(mask > 0)
    pos_ = np.c_[pos_each_axes]
    tree = KDTree(pos_)
    dist, idx = tree.query(spots)
    dist, idx = np.concatenate(dist), np.concatenate(idx)
    clost = pos_[idx, :]
    if centers.shape[1] == 2:
        mask_val = mask[clost[:, 0], clost[:, 1]]
    else:
        mask_val = mask[clost[:, 0], clost[:, 1], clost[:, 2]]
    res = mask_val
    res[dist > dist_th] = 0
    return res


def plot_cell_and_spots(img, mask, signals, colors, number):
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots(1, 2, figsize=(6, 3))

    ax[0].imshow(img)
    ax[0].axis("off")

    bmask = mask > 0
    edges = dilation(bmask > 0, diamond(1)) & ~bmask
    img_spots = img.copy()
    img_spots[edges] = 200 
    ax[1].imshow(img_spots)
    ax[1].axis("off")

    for name, spot in signals.items():
        if len(spot) > 0:  # check if there are spots
            ax[1].scatter(
                spot[:, 1], spot[:, 0], s=20,
                edgecolors='none', c=colors[name], label=name)

    channel_counts = [len(signals[channel]) for channel in signals.keys()]
    text_colors = [colors[channel] for channel in signals.keys()]
    text_items = [
        f"{count}" for _, count in
        zip(signals.keys(), channel_counts)
    ]

    for i, (text, color) in enumerate(zip(text_items, text_colors)):
        fig.text(
            -0.1 + 0.1 * i, 0.15, text, color=color, fontsize=25,
            alpha=0.8, transform=ax[1].transAxes, ha='center', va='top')

    fig.text(
        0.03, 0.97, str(number), color='white', fontsize=30,
        alpha=1, transform=ax[0].transAxes, ha='left', va='top')

    fig.tight_layout(pad=0)
    return fig


def plot_all_rois(rois, masks, signals, colors, max_plots=50):
    selected_index = list(range(len(rois)))
    if len(rois) > max_plots:
        # randomly select max_plots 
        random.shuffle(selected_index)
        selected_index = selected_index[:max_plots]
    rois = [rois[i] for i in selected_index]
    masks = [masks[i] for i in selected_index]
    signals = [signals[i] for i in selected_index]
    num_plots = len(rois)
    rows = int(np.ceil(num_plots / 5))
    cols = min(5, num_plots)
    fig, axs = plt.subplots(rows, cols, figsize=(15, 3*rows), facecolor='k')

    for i, (ax, roi, mask, signal) in enumerate(zip(axs.flat, rois, masks, signals)):
        bmask = mask > 0
        edges = dilation(bmask > 0, diamond(1)) & ~bmask
        img = roi.copy()
        img[edges, :] = 255
        ax.imshow(img)

        for name, spot in signal.items():
            if name in colors and len(spot) > 0:
                ax.scatter(spot[:, 1], spot[:, 0], s=15, edgecolors=colors[name], facecolors="None", linewidths=1, label=name)

        channel_names = list(signal.keys())
        channel_counts = [len(signal[channel]) for channel in channel_names]
        text_colors = [colors.get(channel, 'white') for channel in channel_names]
        text_items = [f"{count}" for count in channel_counts]

        for j, (text, color) in enumerate(zip(text_items, text_colors)):
            ax.text(0.05 + 0.1 * j, 0.12, text, color=color, fontsize=20, alpha=0.8, transform=ax.transAxes, ha='center', va='top')

        ax.text(0.03, 0.97, str(selected_index[i]+1), color='white', fontsize=25, alpha=1, transform=ax.transAxes, ha='left', va='top')
        ax.axis("off")

    for ax in axs.flat[num_plots:]:
        ax.set_facecolor('k')
        ax.axis('off')

    plt.tight_layout()
    return fig


def extract_signal_mask(
        cell_im_ch, cell_spots, quantile=25, square_size=3,
        hard_threshold=None):
    mask = np.zeros_like(cell_im_ch)
    mask[cell_spots[:, 0], cell_spots[:, 1]] = 1
    mask = dilation(mask, square(square_size))
    signals = cell_im_ch[mask > 0]
    threshold = np.percentile(signals, quantile)
    if hard_threshold is not None:
        threshold = np.max([threshold, hard_threshold])
    signal_mask = cell_im_ch > threshold
    return signal_mask


async def get_signal_masks(
        ufish_instance, image, channels,
        quantile=25, square_size=3,
        mask_dilation_size=3,
        hard_threshold=None,
        ):
    signal_masks = []  # signal masks for each channel

    for ch in channels:
        cell_spots = (await call_spots(ufish_instance, image, ch=[ch]))[0]
        cell_im_ch = image[:, :, ch]
        if len(cell_spots) == 0:
            signal_mask = np.zeros_like(cell_im_ch)
        else:
            signal_mask = extract_signal_mask(
                cell_im_ch, cell_spots,
                quantile=quantile, square_size=square_size,
                hard_threshold=hard_threshold)
        signal_mask = dilation(signal_mask, square(mask_dilation_size))
        signal_masks.append(signal_mask)

    merge_mask = reduce(lambda x, y: x & y, signal_masks)
    # signal masks for each channel after subtracting merged mask
    signal_masks_sub = []

    # remove connected components which with overlap with the merged
    for ch_sig_mask in signal_masks:
        signal_masks_sub.append(mask_sub(ch_sig_mask, [merge_mask]))
    signal_masks_sub = np.array(signal_masks_sub)
    return merge_mask, signal_masks_sub


def plot_on_img(img, props):
    import matplotlib.pyplot as plt
    scale = 0.01
    figsize = (img.shape[1] * scale, img.shape[0] * scale)
    fig, ax = plt.subplots(figsize=figsize)
    ax.imshow(img)
    for i, prop in enumerate(props):
        ax.text(
            prop.centroid[1],
            prop.centroid[0],
            f"{i+1}",
            color="white"
        )
    fig.set_tight_layout(True)
    return fig


def fig_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format='png')
    buf.seek(0)
    return base64.b64encode(buf.read()).decode('utf-8')


def filter_cell_by_prop(
        prop,
        img_size,
        area_threshold=1000,
        axis_ratio_threshold=0.5,
        border_threshold=1
        ):
    close_to_edge = False
    if prop.coords[:, 0].min() <= border_threshold or \
            prop.coords[:, 0].max() >= img_size[0] - border_threshold or \
            prop.coords[:, 1].min() <= border_threshold or \
            prop.coords[:, 1].max() >= img_size[1] - border_threshold:
        close_to_edge = True
    if close_to_edge:
        return False
    if prop.area < area_threshold:
        return False
    axis_ratio = prop.minor_axis_length / prop.major_axis_length
    if axis_ratio < axis_ratio_threshold:
        return False
    return True


def filter_cell_by_signals(
        signals, num_thresh_per_channel=3, num_thresh=5):
    count = 0
    for _, signal in signals.items():
        count += signal.shape[0]
        if signal.shape[0] > num_thresh_per_channel:
            return False
    if count < 2:
        return False
    if count > num_thresh:
        return False
    return True


async def pipeline(ufish_instance, img, mask, signal_channels=[0, 1]):
    print("---------- Begin pipeline ----------")
    print(f"Image shape: {img.shape}")
    print(f"Number of cells: {mask.max()}")
    mask = dilation(mask, disk(3))

    print("extract ROIs")
    cell_rois, cell_masks, cell_props = extract_cells(
        img, mask, target_size=128)
    
    print("call signals and assign spots for each cell")
    table = []
    cell_signals = []
    new_cell_rois = []
    new_cell_masks = []
    new_cell_props = []
    filtered_by_prop = []
    filtered_by_signals = []
    for c, cell_roi in enumerate(cell_rois):
        cell_prop = cell_props[c]
        if not filter_cell_by_prop(cell_prop, mask.shape):
            filtered_by_prop.append(c)
            continue
        signal_mask_merge, signal_masks_sub = await get_signal_masks(
            ufish_instance, cell_roi, signal_channels, quantile=10,
            mask_dilation_size=4,
            hard_threshold=30
            )
        signals = {}
        for ch in signal_channels:
            signals[f"ch{ch+1}"] = []
        name = "+".join([f"ch{ch+1}" for ch in signal_channels])
        signals[name] = []
        for i, ch in enumerate(signal_channels):
            single_ch = regionprops(label(signal_masks_sub[i]))
            spots = np.array([cc.centroid for cc in single_ch])
            signals[f"ch{ch+1}"] = spots
        merged = regionprops(label(signal_mask_merge))
        spots = np.array([cc.centroid for cc in merged])
        name = "+".join([f"ch{ch+1}" for ch in signal_channels])
        signals[name] = spots

        if not filter_cell_by_signals(signals):
            filtered_by_signals.append(c)
            continue

        assigns = {}
        for name, spots in signals.items():
            try:
                assigns[name] = assign_spots(spots, cell_masks[c], 30)
            except Exception:
                assigns[name] = []

        df = {
            key: sum(value) for key, value in assigns.items()
            if isinstance(value, np.ndarray)
        }
        df["cell_id"] = f'{c+1}'
        last_key = list(df.keys())[-1]
        last_value = df.pop(last_key)
        df = {last_key: last_value, **df}
        table.append(df)
        cell_signals.append(signals)
        new_cell_rois.append(cell_roi)
        new_cell_masks.append(cell_masks[c])
        new_cell_props.append(cell_props[c])
    print(f"Number of cells filtered by properties: {len(filtered_by_prop)}")
    print(f"Number of cells filtered by signals: {len(filtered_by_signals)}")
    return pd.DataFrame(table).fillna(0), new_cell_rois, new_cell_masks, cell_signals, new_cell_props


ufish_url = "http://localhost:5173/"

class Plugin():
    async def setup(self):
        api.log("dna-ufish utils plugin setup")
        self.res = None

    async def get_ufish_client(self):
        client = await api.getWindow("ufish")
        if (not client):
          client = await api.createWindow({
            src: ufish_url,
            name: "ufish",
            w: 25, h: 6
          })
        await client.setExampleImageUrl(ufish_url + "images/trisomy_example.jpg")
        await client.setOnnxModelUrl(ufish_url + "model/v1.0.1-DNAFISH_model.onnx")
        await client.waitReady()
        return client

    def result_summary(self):
        summary = " ".join([
            "Done",
            f"Number of cells: {len(self.res['table'])}",
            "Results of all cells saved in plugin, prepared for further analysis.",
        ])
        return summary

    async def draw_sample_results(self, max_plots=50):
        if self.res is None:
            return None
        rois = self.res["rois"]
        masks = self.res["masks"]
        signals = self.res["signals"]
        fig = plot_all_rois(
            rois, masks, signals,
            colors={"ch1": "hotpink", "ch2": "lime", "ch1+ch2": "yellow"},
            max_plots=max_plots)
        base64_str = fig_to_base64(fig)
        return base64_str

    async def draw_single_result(self, idx):
        if self.res is None:
            return None
        w = idx
        rois = self.res["rois"]
        masks = self.res["masks"]
        signals = self.res["signals"]
        fig = plot_cell_and_spots(
            rois[w], masks[w], signals[w],
            colors={
                "ch1": "hotpink",
                "ch2": "lime",
                "ch1+ch2": "yellow",
            },
            number=w+1)
        base64_str = fig_to_base64(fig)
        return base64_str

    async def analysis(self, img, mask, signal_channels=[0, 1]):
        uf = await self.get_ufish_client()
        table, rois, masks, signals, props = await pipeline(uf, img, mask, signal_channels)
        self.res = {
            "table": table,
            "rois": rois,
            "masks": masks,
            "signals": signals,
            "props": props
        }
        return self.result_summary()

    async def run(self, ctx):
        pass

api.export(Plugin())
</script>
